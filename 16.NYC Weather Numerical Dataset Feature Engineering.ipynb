{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4506e21a",
   "metadata": {},
   "source": [
    "As already said in the previous [notebook](15.NYC%20Weather%20Categorical%20Dataset%20Feature%20Engineering.ipynb), many of the weather stations did not reported informations for every days. Otherwise, the number of lines in the *weather* dataset would have been 15'106 (\\<number of stations\\> X \\<number of days\\>).\n",
    "\n",
    "\n",
    "Furtermore, I've identified some case where, even if the weather station reported values for a particular day, some of the me4trics where empty.\n",
    "\n",
    "What wouold be nice is to have a complete dataset, replacing missing line and metrics with *coherent* remplacement values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c2e911",
   "metadata": {},
   "source": [
    "What's the strategy I choose to fill missing metrics ? Extension and extrapolation !!\n",
    "\n",
    "- **Extension**: will be the process of creating an extended dataset with the 3'619 mising lines counted above, setting feature values to NaN\n",
    "\n",
    "- **Extrapolation**: will be the process of *extrapolating* the NaN values using non NaN values for the same day.\n",
    "\n",
    "More details on how to do that trick in the following cells of this Notebook.\n",
    "\n",
    "Let's go :-)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2b36eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening connection to database\n",
      "Add pythagore() function to SQLite engine\n",
      "Fraction of the dataset used to train models: 10.00%\n",
      "my_utils library loaded :-)\n"
     ]
    }
   ],
   "source": [
    "# Load my_utils.ipynb in Notebook\n",
    "from ipynb.fs.full.my_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ac036c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load current weather_num table in Dataframe\n",
    "df=load_sql('weather_num', verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "167fc51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing lines in the weather dataset:  3619\n"
     ]
    }
   ],
   "source": [
    "# Get number of lines from dataset\n",
    "number_of_lines=len(df.index)\n",
    "\n",
    "# Calculate number of lines if all the STATION had reported values\n",
    "expected_number_of_lines=len(get_stations().index) * len(get_days()) # get_days() comes from my_utils library\n",
    "\n",
    "# Print the difference\n",
    "print(\"Number of missing lines in the weather dataset: \", expected_number_of_lines - number_of_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98950fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values per feature in dataset:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TSTD       9077\n",
       "TAVG       9077\n",
       "SNWD       8420\n",
       "SNOW       4536\n",
       "PRCP        200\n",
       "AWND          0\n",
       "DATE          0\n",
       "STATION       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the NaN values per feature\n",
    "print(\"Number of NaN values per feature in dataset:\")\n",
    "df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75a7d7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table name used to save the improved dataset: weather_num_improved\n"
     ]
    }
   ],
   "source": [
    "# Verify SQL tablename is defined in my_utils library\n",
    "print(\"Table name used to save the improved dataset:\", WEATHER_NUM_TABLENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860c48e1",
   "metadata": {},
   "source": [
    "# Extension: Build an extended dataset\n",
    "\n",
    "The goal here is to extend the *weather_num* dataset with the 3'619 missing line, filling new line features with np.nan values.\n",
    "The result will be a dataset of 83 stations x 182 days = 15106 lines.\n",
    "\n",
    "To do so, I will first create an empty DataFrame with the same columns as *weather_num*.\n",
    "\n",
    "Then, I will use the *get_days()* function from [my_utils](my_utils.ipynb) library to create a loop on every days, and for each of them i will :\n",
    "\n",
    "1. Select all the lines for that day from *weather_num* table of my database\n",
    "\n",
    "2. Append the result to my empty DataFrame\n",
    "\n",
    "3. Select *STATION* from *stations* table which **are not** in the lines selected in point (1), appended with the current day\n",
    "\n",
    "4. Append this second query result to my empty DataFrame.\n",
    "\n",
    "At the end of the loop, I should have a 15'106 lines dataset, one line for each *DATE* and *STATION* :-)\n",
    "\n",
    "Here are the SQL described above for day = '2016-01-01':\n",
    "\n",
    "    (1) SELECT * FROM weather_num WHERE DATE='2016-01-01'\n",
    "\n",
    "    (2) SELECT STATION, '2016-01-01' AS DATE FROM stations WHERE STATION NOT IN ('US1NYWC0003','US1NJBG0023', [...],'USW00054787')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e75fd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty global dataset\n",
    "stations_and_day_df=pd.DataFrame(columns=df.columns)\n",
    "\n",
    "# Loop for each days from '2016-01-01' to '2016-01-01'\n",
    "for date in get_days():\n",
    "    \n",
    "    # Select lines for current date loop\n",
    "    query=f\"SELECT * FROM weather_num WHERE DATE='{date}'\"\n",
    "    \n",
    "    # Store result in temp_df\n",
    "    temp_df=load_sql(query=query, verbose=False)\n",
    "    \n",
    "    # Append temp_df to global dataset\n",
    "    stations_and_day_df=stations_and_day_df.append(temp_df, ignore_index=True, sort=False)\n",
    "\n",
    "    # Select STATION that are not in the temp_df dataset, appending 'date' to result\n",
    "    query=\"SELECT STATION, '{}' AS DATE FROM stations WHERE STATION NOT IN ('{}')\".format(date,\"','\".join(temp_df['STATION']))\n",
    "\n",
    "    # Run query and append result to global dataset\n",
    "    stations_and_day_df=stations_and_day_df.append(load_sql(query=query, verbose=False), ignore_index=True, sort=False)\n",
    "    \n",
    "# Copy result in a new dataset that will be used in the cells below: weather_df_extended\n",
    "weather_df_extended=stations_and_day_df.sort_values(by=['DATE', 'STATION'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae8bfb8",
   "metadata": {},
   "source": [
    "Let's check the number of lines in our dataset, and the number of NaN value per feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b690bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines in extended dataset: 15106\n",
      "Number of NaN values per feature in dataset:\n",
      "TSTD       12696\n",
      "TAVG       12696\n",
      "SNWD       12039\n",
      "SNOW        8155\n",
      "PRCP        3819\n",
      "AWND        3619\n",
      "DATE           0\n",
      "STATION        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display the number of lines, should be 15'106\n",
    "print(\"Number of lines in extended dataset:\", len(weather_df_extended.index))\n",
    "\n",
    "# Display the NaN values per feature\n",
    "print(\"Number of NaN values per feature in dataset:\")\n",
    "print(weather_df_extended.isna().sum().sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e93c3f",
   "metadata": {},
   "source": [
    "Well done, I have now a dataset with a line for each *DATE* and *STATION*.\n",
    "\n",
    "Let's go on with the next part, extrapolation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad5fb4e",
   "metadata": {},
   "source": [
    "# Extrapolation: Fill missing values with extrapolated one\n",
    "\n",
    "What is *extrapolation* ?\n",
    "\n",
    "As we are talking here about numerical values that are *continuous*, I've decided to fill in the NaN cells with the average values of the maximum three nearest weather stations of the concerned cells.\n",
    "\n",
    "To do so, I've written a function, *get_nan_replacement_value()*, which is detailed in the next cell.\n",
    "\n",
    "This function simply returns the replacement value for a cell using three parameters:\n",
    "- station: The weather station we are looking for replacement value.\n",
    "- date: the date of the replacement value.\n",
    "- feature: The name of the feature we would like to replace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6420e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nan_replacement_value(station, date, feature) -> float:\n",
    "    \"\"\"\n",
    "    Returns a replacement value for the 'feature' received as parameter using the average\n",
    "    of the maximum three nearest stations, for the 'station' and 'date' received as parameter\n",
    "    \n",
    "    Here is the algorythm choosen:\n",
    "    \n",
    "    - Performs a SQL SELECT in weather_num where feature is not null.\n",
    "    - In the previous SELECT, used the pythagore() method two identify the nearest three stations\n",
    "    - Form the previous result, performs a SELECT AVG(feature). This will calculate the average of \n",
    "      the maximum three values from the nearest weather station.\n",
    "    - Use Dataframe.at() method to retrieve the average value we are looking for, and return it.\n",
    "    \n",
    "    Parameters are:\n",
    "    - station: The weather station we are looking for replacement value.\n",
    "    - date: the date of the replacement value.\n",
    "    - feature: The name of the feature we would like to replace.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # First get location of 'station' passed as parameter\n",
    "    station_df=get_stations(station_list=[station])[['LATITUDE', 'LONGITUDE']]\n",
    "    station_latitude=float(station_df.LATITUDE.values[0])\n",
    "    station_longitude=float(station_df.LONGITUDE.values[0])\n",
    "    \n",
    "    # Build first SQL queries (the one who gets the 3 nearest weather station with their 'feature' values)\n",
    "    query='SELECT '\n",
    "    query+=f\"W.STATION, S.LATITUDE, S.LONGITUDE, W.DATE, W.{feature}, '{station_latitude}', '{station_longitude}' \"\n",
    "    query+=f\"FROM weather_num AS W \"\n",
    "    query+=f\"INNER JOIN stations AS S ON S.STATION=W.STATION \"\n",
    "    query+=f\"WHERE DATE='{date}' AND {feature} IS NOT NULL \"\n",
    "    query+=f\"ORDER BY pythagore({station_longitude}, {station_latitude}, S.LATITUDE, S.LONGITUDE) ASC LIMIT 3\"\n",
    "    \n",
    "    # Create second SQL query, based on the previous query, to get average of the feature\n",
    "    query=f\"SELECT avg({feature}) AS {feature} FROM ({query})\"\n",
    "    \n",
    "    # Get the value we are looking for\n",
    "    df=load_sql(query=query, verbose=False)\n",
    "    \n",
    "   \n",
    "    return df[feature].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef40f2d",
   "metadata": {},
   "source": [
    "I'll then loop on each numerical features and apply the *get_nan_replacement_value()* to all cells of the feature that are empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e76d9983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Extrapolation process starting ==\n",
      "Extrapolating value for feature AWND\n",
      "  Number of NaN values in dataset: 3619\n",
      "  Processing done\n",
      "  Number of NaN values after extrapolation: 0\n",
      "Extrapolating value for feature PRCP\n",
      "  Number of NaN values in dataset: 3819\n",
      "  Processing done\n",
      "  Number of NaN values after extrapolation: 0\n",
      "Extrapolating value for feature SNOW\n",
      "  Number of NaN values in dataset: 8155\n",
      "  Processing done\n",
      "  Number of NaN values after extrapolation: 0\n",
      "Extrapolating value for feature SNWD\n",
      "  Number of NaN values in dataset: 12039\n",
      "  Processing done\n",
      "  Number of NaN values after extrapolation: 0\n",
      "Extrapolating value for feature TAVG\n",
      "  Number of NaN values in dataset: 12696\n",
      "  Processing done\n",
      "  Number of NaN values after extrapolation: 0\n",
      "Extrapolating value for feature TSTD\n",
      "  Number of NaN values in dataset: 12696\n",
      "  Processing done\n",
      "  Number of NaN values after extrapolation: 0\n",
      "== Extrapolation process terminated ==\n"
     ]
    }
   ],
   "source": [
    "# Crete a copy of our extended dataset\n",
    "weather_num_extrapolated=weather_df_extended.copy()\n",
    "\n",
    "# Some logging informations\n",
    "print(\"== Extrapolation process starting ==\")\n",
    "\n",
    "# Loop on each numerical features\n",
    "for feature in weather_df_extended.columns[2:]:\n",
    "    \n",
    "    # Disaply information on current feature processed\n",
    "    print(\"Extrapolating value for feature\", feature)\n",
    "    \n",
    "    # Display number of NaN values before extrapolation\n",
    "    print(\"  Number of NaN values in dataset:\",weather_num_extrapolated[feature].isna().sum())\n",
    "    \n",
    "    # Build a filter on current feature NaN values\n",
    "    filter_nan=weather_num_extrapolated[feature].isna()\n",
    "\n",
    "    # Apply get_nan_replacement_value() on filtered feature\n",
    "    weather_num_extrapolated[feature]=weather_num_extrapolated.apply(lambda x: get_nan_replacement_value(x['STATION'], x['DATE'], feature) if(pd.notnull(x[feature]) == False) else x[feature], axis=1)\n",
    "\n",
    "    # Display logging informations\n",
    "    print(\"  Processing done\")\n",
    "    \n",
    "    # Display number of NaN values after extrapolation\n",
    "    print(\"  Number of NaN values after extrapolation:\",weather_num_extrapolated[feature].isna().sum())\n",
    "\n",
    "# Display logging informations\n",
    "print(\"== Extrapolation process terminated ==\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a4fab9",
   "metadata": {},
   "source": [
    "Ok, let's display the first 3 lines of the *weather_num* dataset **before** and **after** the extrapolation, as well as the number of lines and the number of NaN values in the extrapolated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "678662ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather_num dataset BEFORE extrapolation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>AWND</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TSTD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>US1CTFR0022</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>US1CTFR0039</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>US1NJBG0002</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        STATION        DATE  AWND  PRCP  SNOW  SNWD  TAVG  TSTD\n",
       "77  US1CTFR0022  2016-01-01   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "79  US1CTFR0039  2016-01-01   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "38  US1NJBG0002  2016-01-01   0.0   0.3   NaN   NaN   NaN   NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Weather_num dataset BEFORE extrapolation:\")\n",
    "weather_df_extended.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "766216dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather_num dataset AFTER extrapolation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>AWND</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TSTD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>US1CTFR0022</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>2.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>US1CTFR0039</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>2.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>US1NJBG0002</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>2.233333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        STATION        DATE  AWND  PRCP  SNOW  SNWD      TAVG      TSTD\n",
       "77  US1CTFR0022  2016-01-01   1.3   0.0   0.0   0.0  4.833333  2.233333\n",
       "79  US1CTFR0039  2016-01-01   1.3   0.0   0.0   0.0  4.833333  2.233333\n",
       "38  US1NJBG0002  2016-01-01   0.0   0.3   0.0   0.0  4.833333  2.233333"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Weather_num dataset AFTER extrapolation:\")\n",
    "weather_num_extrapolated.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3db46a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines in extended dataset (must be equal to 15'106): 15106\n",
      "Number of NaN values per feature in dataset (must be all equal to 0):\n",
      "TSTD       0\n",
      "TAVG       0\n",
      "SNWD       0\n",
      "SNOW       0\n",
      "PRCP       0\n",
      "AWND       0\n",
      "DATE       0\n",
      "STATION    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display the number of lines, should be 15'106\n",
    "print(\"Number of lines in extended dataset (must be equal to 15'106):\", len(weather_num_extrapolated.index))\n",
    "\n",
    "# Display the NaN values per feature\n",
    "print(\"Number of NaN values per feature in dataset (must be all equal to 0):\")\n",
    "print(weather_num_extrapolated.isna().sum().sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f2b023",
   "metadata": {},
   "source": [
    "Nice, NaN values have been replaced by extrapolated ones.\n",
    "\n",
    "And trust me, the *get_nan_replacement_value()* function works the way I wanted to ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e20b83",
   "metadata": {},
   "source": [
    "# Save extrapolated dataset to SQL database\n",
    "\n",
    "It's now time to save the result as a new dataset in our SQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bddfffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save extrapolated dataset to SQL database\n",
    "save_sql(dataset=weather_num_extrapolated, tablename=WEATHER_NUM_TABLENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf9cb4c",
   "metadata": {},
   "source": [
    "Time to continue with the next notebook: [The global Dataset - Merging all the datasets into a big one](17.The%20global%20Dataset%20-%20Merging%20all%20the%20datasets%20into%20a%20big%20one.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
