{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25f51de7",
   "metadata": {},
   "source": [
    "# The datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3519f9",
   "metadata": {},
   "source": [
    "This capstone project is based on two datasets, *NYC Taxi Travel* and *NYC Weather* datasets. You can find more details on their origin in the [Introduction Notebook](./00.%20Introduction.ipynb) Notebook.\n",
    "\n",
    "Here is a description of their structure and some quick cleanup actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a153ba",
   "metadata": {},
   "source": [
    "## NYC Taxi Travel Dataset\n",
    "\n",
    "This dataset is made of 11 columns, which contains 10 independent variables and one dependent.\n",
    "\n",
    "The 10 independent variables will be part of the final dataset features, and the dependent one will be used to create my result vector: *km_per_hour*\n",
    "\n",
    "Here is a description of the variables.\n",
    "\n",
    "### Independent variables\n",
    "\n",
    "* id - a unique identifier for each trip.\n",
    "* vendorid - a code indicating the provider associated with the trip record.\n",
    "* pickupdatetime - date and time when the meter was engaged.\n",
    "* dropoffdatetime - date and time when the meter was disengaged.\n",
    "* passengercount - the number of passengers in the vehicle (driver entered value).\n",
    "* pickuplongitude - the longitude where the meter was engaged\n",
    "* pickuplatitude - the latitude where the meter was engaged\n",
    "* dropofflongitude - the longitude where the meter was disengaged\n",
    "* dropofflatitude - the latitude where the meter was disengaged\n",
    "* store_and_fwd_flag — This flag indicates whether the trip record was held in vehicle memory before sending to the vendor because the vehicle did not have a connection to the server — Y=store and forward; N=not a store and forward trip.\n",
    "\n",
    "### Dependent variable\n",
    "\n",
    "* trip_duration — duration of the trip in seconds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4df794f",
   "metadata": {},
   "source": [
    "## NYC Weather Dataset\n",
    "\n",
    "This dataset is made of 11'544 lines with 66 columns. Each line contains the daily values for a particular weather station regarding weather informations: temperature, rain, snow, wind, ...\n",
    "\n",
    "What I will have to do first with this dataset is to extract the list of the different weather stations along with their locations. This weather station list will be merged with the NYC Travel one, using the weather stations coordinates to determine which one is the nearest from pickup and dropoff.\n",
    "\n",
    "Here is a description of the variables.\n",
    "\n",
    "### Weather station static informations\n",
    "- STATION - Identification of the weather station\n",
    "- NAME - The name of the weather station\n",
    "- LATITUDE - Latitude of the weather station\n",
    "- LONGITUDE - Logitude of the weather station\n",
    "- ELEVATION - Elevation\n",
    "\n",
    "### Independent variables\n",
    "- DATE - Date when the measures where done (YYYY-MM-DD)\n",
    "- AWND - Average wind speed\n",
    "- DAPR - Number of days included in the multiday precipitation total (MDPR)\n",
    "- DASF - Number of days included in the multiday snow fall total (MDSF) \n",
    "- MDPR - Multiday precipitation total (use with DAPR and DWPR, if available)\n",
    "- MDSF - Multiday snowfall total \n",
    "- PGTM - Peak gust time\n",
    "- PRCP - Precipitation\n",
    "- PSUN - Daily percent of possible sunshine for the period\n",
    "- SNOW - Snowfall\n",
    "- SNWD - Snow depth\n",
    "- TAVG - Average Temperature.\n",
    "- TMAX - Maximum temperature\n",
    "- TMIN - Minimum temperature\n",
    "- TOBS - Temperature at the time of observation\n",
    "- TSUN - Total sunshine for the period\n",
    "- WDF2 - Direction of fastest 2-minute wind\n",
    "- WDF5 - Direction of fastest 5-second wind\n",
    "- WESD - Water equivalent of snow on the ground\n",
    "- WESF - Water equivalent of snowfall\n",
    "- WSF2 - Fastest 2-minute wind speed\n",
    "- WSF5 - Fastest 5-second wind speed\n",
    "- WT01 - Fog, ice fog, or freezing fog (may include heavy fog)\n",
    "- WT02 - Heavy fog or heaving freezing fog (not always distinguished from fog)\n",
    "- WT03 - Thunder\n",
    "- WT04 - Ice pellets, sleet, snow pellets, or small hail\" \n",
    "- WT05 - Hail (may include small hail)\n",
    "- WT06 - Glaze or rime \n",
    "- WT08 - Smoke or haze \n",
    "- WT09 - Blowing or drifting snow\n",
    "- WT11 - High or damaging winds\n",
    "\n",
    "\n",
    "\n",
    "> Note: There is no dependent variable in this dataset as all the column will be used to add features to the NYC Taxi Travel dataset.\n",
    "\n",
    "> Note 2: All the units in this dataset are in metric standard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd9d89a",
   "metadata": {},
   "source": [
    "# Table of content\n",
    "\n",
    "Data preparation is splitted into seven Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ba6dd8",
   "metadata": {},
   "source": [
    "## [The 83 Weather Stations](11.The%2083%20Weather%20Stations.ipynb)\n",
    "\n",
    "In the NYC Weather Dataset, I've found what I've called *static weather station data*:\n",
    "- STATION - Identification of the weather station\n",
    "- NAME - The name of the weather station\n",
    "- LATITUDE - Latitude of the weather station\n",
    "- LONGITUDE - Logitude of the weather station\n",
    "- ELEVATION - Elevation\n",
    "\n",
    "Those static data generates a lot of duplicated data into the dataset as there is a total of 83 different weather stations in the whole dataset.\n",
    "\n",
    "The goal of this Notebook is to create a small dataset that contains the static features of the weather stations.\n",
    "\n",
    "## [NYC Taxi Travel Data Preparation](12.NYC%20Taxi%20Travel%20Data%20Preparation.ipynb)\n",
    "\n",
    "This first Notebook prepares data grabbed from Kaggle, containing the Taxi Travel informations. Most of the work here will be to remove useless columns, outliers and prepare data for the rest of the project.\n",
    "\n",
    "As this dataset has been found already cleaned, this work will be quite straight forward.\n",
    "\n",
    "One question you may have reading this [NYC Taxi Travel Data Preparation](12.NYC%20Taxi%20Travel%20Data%20Preparation.ipynb) Notebook is how I've choosen the latitude/logitude values that I will use to remove some pickup and dropoff points from the project ? Well, looking at the weather stations locations available into the NYC Weather Datasets, I've decided to match the travel location with the weather station ones.\n",
    "\n",
    "We'll see that this approach did not remove a lot of lines from NYC Taxi Travel Dataset (less than 6'000 over ~1'500'000), and will be more efficient when I will merge the two dataset. As I would like to match pickup and dropoff location to the nearest weather station, removing travel location far away from stations makes sense.\n",
    "\n",
    "## [NYC Weather Data Preparation](13.NYC%20Weather%20Data%20Preparation.ipynb)\n",
    "\n",
    "This Notebook contains the data preparation process of the independent features of the NYC Weather Dataset.\n",
    "\n",
    "After cleaning up the dataset (drop some useless columns), most of the work will be focused on creating two datasets from this one:\n",
    "\n",
    "- Weather Categorical dataset\n",
    "    \n",
    "This dataset will be built using features that are defined as categories: Wind direction, fog, peak ust,...\n",
    "\n",
    "We'll see later in this project that this dataset will be grouped by days instead of weather station locations.\n",
    "    \n",
    "- Weather Numerical dataset\n",
    "\n",
    "This second dataset will contains all the numerical values of the measures taken by the stations: Temperature, precipitation, snow...\n",
    "\n",
    "This dataset will be grouped by weather station and date, and we will discover that not all the data is available for each station/day. We will see how to solve this.\n",
    "\n",
    "## [NYC Taxi Travel Dataset Feature Engineering](14.NYC%20Taxi%20Travel%20Dataset%20Feature%20Engineering.ipynb)\n",
    "\n",
    "With this third dataset, which is the biggest one, I will try to engineer some interesting features, using static data informations from the 83 weather stations:\n",
    "- Distance from nearest weather station\n",
    "- Distance in kilometers between pickup and dropoff locations\n",
    "- ...\n",
    "\n",
    "It's in this Notebook that I will build my result vector: *km_per_hour*\n",
    "\n",
    "## [NYC Weather Categorical Dataset Feature Engineering](15.NYC%20Weather%20Categorical%20Dataset%20Feature%20Engineering.ipynb)\n",
    "\n",
    "The *Weather Categorical* dataset will be grouped by days in this Notebook. This will produce a dataset with 182 lines, which is the number of days between the 1st of January 2016 and the 30th of June 2016.\n",
    "\n",
    "Reason of this approach will be explained in the notebook.\n",
    "\n",
    "## [NYC Weather Numerical Dataset Feature Engineering](16.NYC%20Weather%20Numerical%20Dataset%20Feature%20Engineering.ipynb)\n",
    "\n",
    "In this Notebook, the *Weather Numerical* dataset, before being grouped by days and by weather stations, will be extended and the missing values extrapolated.\n",
    "\n",
    "- Extended: To add missing tuple of (days, weather stations)\n",
    "\n",
    "- Extrapolated: To fill the weather stations NaN values using the average of the *n* nearest non null weather stations values.\n",
    "\n",
    "The whole extension and extrapolation process will be described in this Notebook.\n",
    "\n",
    "This will produce a dataset with 15'106 lines, which is the number of days (182) multiplied by the number of weather stations (83).\n",
    "\n",
    "\n",
    "## [The global Dataset - Merging all the datasets into a big one](17.The%20global%20Dataset%20-%20Merging%20all%20the%20datasets%20into%20a%20big%20one.ipynb)\n",
    "\n",
    "After all this cleaning and feature engineering process on the two original dataset, it will be time to merge all of the datasets produced in previous Notebooks:\n",
    "\n",
    "- Taxi Travel dataset\n",
    "- Weather Stations Dataset\n",
    "- Weather Categorical Dataset\n",
    "- Weather Numerical Dataset\n",
    "\n",
    "This will result in a *full* dataset ready for ML training process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b01ad3",
   "metadata": {},
   "source": [
    "# Overview of the created datasets\n",
    "\n",
    "Af the end of data cleaning and feature engineering, I will obtain four datasets:\n",
    "\n",
    "1. *stations* dataset\n",
    "\n",
    "A dataset with all the static informations of the weather stations like elevation, latitude, name.\n",
    "\n",
    "2. *travel* dataset\n",
    "\n",
    "A *feature engineered* dataset of the *NYC Taxi Travel dataset* like pickup_datetime, dropoff_location\n",
    "\n",
    "3. *weather categorical* dataset\n",
    "\n",
    "Categorical feature per day, *engineered* from the weather stations dataset like snow fall, fog.\n",
    "\n",
    "4. *weather numerical* dataset\n",
    "\n",
    "Numerical feature per day and per weather stations, *engineered* from the weather stations dataset like temperature average, quantity of snow on the road\n",
    "\n",
    "5. Full dataset\n",
    "\n",
    "This dataset is a merge of the *numerical* and *categorical* features of the four previous dataset, ready to be used with ML training processes.\n",
    "\n",
    "> Note: Construction and description of these dataset will be detailed in the following Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5638577d",
   "metadata": {},
   "source": [
    "# Technics\n",
    "\n",
    "To perform the merge of the data, I've decided to use an *sqlite* database approach and play with *INNER JOIN* methods to merge datasets.\n",
    "\n",
    "This technic will be used in the [The global Dataset - Merging all the datasets into a big one](17.The%20global%20Dataset%20-%20Merging%20all%20the%20datasets%20into%20a%20big%20one.ipynb) to build the *Full* dataset\n",
    "\n",
    "Stay tuned ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90578c25",
   "metadata": {},
   "source": [
    "# Let's go\n",
    "\n",
    "Time to go to the first data preparation Notebook: [The 83 Weather Stations](11.The%2083%20Weather%20Stations.ipynb) :-)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
