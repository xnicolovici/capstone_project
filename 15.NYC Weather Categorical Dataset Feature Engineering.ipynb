{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d8b2323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening connection to database\n",
      "Add pythagore() function to SQLite engine\n",
      "Fraction of the dataset used to train models: 10.00%\n",
      "my_utils library loaded :-)\n"
     ]
    }
   ],
   "source": [
    "# Load my_utils.ipynb in Notebook\n",
    "from ipynb.fs.full.my_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc801ca",
   "metadata": {},
   "source": [
    "# Group dataset by *DATE*\n",
    "\n",
    "What kind of feature engineering could I do on the categorical features build from my weather dataset ?\n",
    "\n",
    "Well, most of the work has been done while bulding this categorical dataset (refer to [NYC Weather Data Preparation](13.NYC%20Weather%20Data%20Preparation.ipynb) notebook for more details), but there's one last thing I've decided to do: Group all those categorical features by day.\n",
    "\n",
    "Looking at my *weather_cat* dataset, I've found that some weather stations did not reported any metrics for some days and moreover, some stations did not reported always all of their metrics: Were thay out of order ? Stopped for maintenance ? Not equiped to measure some features others do ?\n",
    "\n",
    "Whatever the reason, it would be nice to have a complete dataset, and for that reason, I've decided to drop the *STATION* feature and group by *DATE* the lines in the *weather_cat* dataset. Doing so, I'll get a dataset with one line per day, and categorical feature set for that day.\n",
    "\n",
    "To perform this *grouping* operation, I will use an SQL SELECT query to group by *DATE*, and grab the max value of the other columns. As the value are either 0 or 1, taking the max will set the feature to 1 if at least one of the *STATION* for this *DATE* reported 1 for the considered feature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2db7304",
   "metadata": {},
   "source": [
    "## What will be the result ?\n",
    "\n",
    "Grouping by DATE, taking for each categorical feature the maximum value of each of them, and droping the *STATION* feature, I'll obtain a dataset of 182 lines, which is the number of days between the 1st of January 2016 and the 30th of June 2016.\n",
    "\n",
    "Of course, some of the features might be multivaluated, in the sense that taking, for one particular *DATE*, the max value of each WDIR_* feature, it might result in a day with multiple wind directions.\n",
    "\n",
    "Is that a problem ? I don't think so. Furthermore, it would be far more complicated and error prone to try to extrapolate features on missing entries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc7971a",
   "metadata": {},
   "source": [
    "## Let's do it...\n",
    "\n",
    "And start by verifying that the name of the SQL tablename is defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5935edfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table name used to save the improved dataset: weather_cat_improved\n"
     ]
    }
   ],
   "source": [
    "# Verify SQL tablename is defined in my_utils library\n",
    "print(\"Table name used to save the improved dataset:\", WEATHER_CAT_TABLENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c589dbda",
   "metadata": {},
   "source": [
    "Load the *weather_cat* dataset built in [NYC Weather Data Preparation](13.NYC%20Weather%20Data%20Preparation.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8c6e187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SELECT * FROM weather_cat\n"
     ]
    }
   ],
   "source": [
    "# Load weather categorical dataset from SQL Database\n",
    "df=load_sql('weather_cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cd62a9",
   "metadata": {},
   "source": [
    "Verify that I do not have any NaN value in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e835b531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in dataset:  0\n"
     ]
    }
   ],
   "source": [
    "# Check there is no NaN values\n",
    "print(\"Number of NaN values in dataset: \", df.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec681c55",
   "metadata": {},
   "source": [
    "Run the following query that will group line by *DATE*, dropping *STATION* column and keeping the MAX() value of the other ones:\n",
    "\n",
    "    SELECT\n",
    "    DATE,\n",
    "    MAX(WT01) AS WT01,\n",
    "    MAX(WT02) AS WT02,\n",
    "    MAX(WT03) AS WT03,\n",
    "    MAX(WT04) AS WT04,\n",
    "    MAX(WT06) AS WT06,\n",
    "    MAX(WT08) AS WT08,\n",
    "    MAX(WT09) AS WT09,\n",
    "    MAX(WT11) AS WT11,\n",
    "    MAX(WDIR_E) AS WDIR_E,\n",
    "    MAX(WDIR_N) AS WDIR_N,\n",
    "    MAX(WDIR_NE) AS WDIR_NE,\n",
    "    MAX(WDIR_NW) AS WDIR_NW,\n",
    "    MAX(WDIR_S) AS WDIR_S,\n",
    "    MAX(WDIR_SE) AS WDIR_SE,\n",
    "    MAX(WDIR_SW) AS WDIR_SW,\n",
    "    MAX(WDIR_W) AS WDIR_W,\n",
    "    MAX(PEAK_Y) AS PEAK_Y,\n",
    "    MAX(SNOW_FALL) AS SNOW_FALL,\n",
    "    MAX(SNOW_ROAD) AS SNOW_ROAD\n",
    "    FROM weather_cat\n",
    "    GROUP BY DATE ORDER BY DATE ASC\n",
    "\n",
    "> Note: Column built with the MAX() function are renamed to keep the same feature names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0beae4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>WT01</th>\n",
       "      <th>WT02</th>\n",
       "      <th>WT03</th>\n",
       "      <th>WT04</th>\n",
       "      <th>WT06</th>\n",
       "      <th>WT08</th>\n",
       "      <th>WT09</th>\n",
       "      <th>WT11</th>\n",
       "      <th>WDIR_E</th>\n",
       "      <th>WDIR_N</th>\n",
       "      <th>WDIR_NE</th>\n",
       "      <th>WDIR_NW</th>\n",
       "      <th>WDIR_S</th>\n",
       "      <th>WDIR_SE</th>\n",
       "      <th>WDIR_SW</th>\n",
       "      <th>WDIR_W</th>\n",
       "      <th>PEAK_Y</th>\n",
       "      <th>SNOW_FALL</th>\n",
       "      <th>SNOW_ROAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE  WT01  WT02  WT03  WT04  WT06  WT08  WT09  WT11  WDIR_E  WDIR_N  WDIR_NE  WDIR_NW  \\\n",
       "0  2016-01-01     0     0     0     0     0     0     0     0       0       0        0        1   \n",
       "1  2016-01-02     0     0     0     0     0     0     0     0       0       0        0        0   \n",
       "2  2016-01-03     0     0     0     0     0     1     0     0       0       0        0        0   \n",
       "\n",
       "   WDIR_S  WDIR_SE  WDIR_SW  WDIR_W  PEAK_Y  SNOW_FALL  SNOW_ROAD  \n",
       "0       0        0        0       1       1          0          0  \n",
       "1       0        0        0       1       1          0          0  \n",
       "2       0        0        1       1       1          0          0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build query described above\n",
    "query = 'SELECT DATE'\n",
    "\n",
    "# Loop for each column name except STATION and DATE ([1:2])\n",
    "for col in list(df.columns[2:]):\n",
    "    query+=f', MAX({col}) AS {col}'\n",
    "\n",
    "# Finalize query\n",
    "query+=\" FROM weather_cat WHERE DATE!='2016-07-01' GROUP BY DATE ORDER BY DATE ASC\"\n",
    "\n",
    "# Run query\n",
    "df=load_sql(query=query, verbose=False)\n",
    "\n",
    "# Display some lines\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c792e4",
   "metadata": {},
   "source": [
    "Check that the number of lines and columns is correct.\n",
    "\n",
    "- Number of line must be 182, it's the number of days between the 1st of January 2016 and the 30th of June 2016\n",
    "\n",
    "- Number of column must be 20, 1 less that the *weather_cat* dataset as we've removed the *STATION* feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a34f1dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines and columns in dataset is correct: 182 x 20\n"
     ]
    }
   ],
   "source": [
    "# Get number of lines:\n",
    "number_of_lines=len(df.DATE)\n",
    "\n",
    "# Get number of column:\n",
    "number_of_columns=len(df.columns)\n",
    "\n",
    "if (number_of_lines==182 and number_of_columns==20) : # Number of lines and columns matches\n",
    "    print(\"Number of lines and columns in dataset is correct: {} x {}\".format(number_of_lines, number_of_columns))\n",
    "else:\n",
    "    print(\"ERROR: Number of lines and columns in dataset is incorrect: {} x {}\".format(number_of_lines, number_of_columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3792250e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save improved dataset to SQL Database\n",
    "save_sql(df, tablename=WEATHER_CAT_TABLENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b239af",
   "metadata": {},
   "source": [
    "# Go to next...\n",
    "\n",
    "...notebook: [NYC Weather Numerical Dataset Feature Engineering](16.NYC%20Weather%20Numerical%20Dataset%20Feature%20Engineering.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
